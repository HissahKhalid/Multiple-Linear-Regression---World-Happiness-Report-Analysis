# -*- coding: utf-8 -*-
"""Task6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DRNQvJrRTs0uprpBKkIU3j6zNjuq_OnU
"""

# Task\            6-Multiple Linear Regression
# DataSet name\    {World Happiness Report}
# Source\          https://www.kaggle.com/datasets/unsdsn/world-happiness/data
# Developer\       {Hissah Almuhaysh}
# Supervisor\      {Engineer Mohammed Hussein}
# Date\            8-2024

# 1. Understanding Multiple Linear Regression:
    # Explain the concept of Multiple Linear Regression. What are the main differences between simple linear regression and multiple linear regression?
"""
    1. Simple Linear Regression
          Definition: A statistical method to predict a dependent variable based on one independent variable, establishing a linear relationship between them.
          Example: Predicting weight based on height.

    2. Multiple Linear Regression
          Definition: A statistical model to predict a dependent variable using multiple independent variables, capturing more complex relationships.
          Example: Predicting a household's electricity bill based on the number of residents, house size, air conditioning usage, and number of appliances.
"""

# 2. Model Interpretation:
     # Consider a Multiple Linear Regression model where the dependent variable is house prices, and the independent variables include the number of bedrooms, square footage, and age of the house.
     # Explain how each independent variable might influence the house prices.
"""
      Interpreting the Impact of Factors on Price:
      1- Number of Rooms: More rooms add value, like stacking treasures; typically, more rooms mean a higher price.
      2- Area: A larger area is like a bigger canvasâ€”more space usually equals a higher price.
      3- Age of the House: Older homes may lose appeal over time, often leading to a lower price unless well-maintained or in a prime location.
"""

# Data Collection: {World Happiness Report}
""" Find a simple dataset that includes multiple independent variables and one dependent variable. You can search for
    datasets on platforms like Kaggle, UCI Machine Learning Repository, or any other open-source dataset provider. """

# 1. Data Preprocessing:
""" Clean and preprocess the dataset. This includes handling missing values,
    encoding categorical variables (if any), and normalizing/standardizing the data."""

# Import libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Load the dataset
url = "/content/World_Happiness_Report.csv"
df = pd.read_csv(url)

# Display the first few rows of the dataset
print("First few rows of the dataset:")
print(df.head())

# Handle missing values (if any)
print("\nChecking for missing values:")
print(df.isnull().sum())

# Drop missing values (if any)
df = df.dropna()

# Encoding categorical variables (if needed)
# Since the dataset contains regions, we will encode them using one-hot encoding
df = pd.get_dummies(df, columns=['Region'], drop_first=True)

# Normalize/Standardize the data (for continuous variables)
scaler = StandardScaler()
df[['Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)', 'Freedom', 'Trust (Government Corruption)']] = scaler.fit_transform(
    df[['Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)', 'Freedom', 'Trust (Government Corruption)']])

# 2. Exploratory Data Analysis (EDA):
"""Perform an EDA to understand the relationships between the independent variables and the
   dependent variable. Visualize these relationships using plots (scatter plots, correlation heatmap, etc.)."""

# Select only numeric columns for correlation
numeric_df = df.select_dtypes(include=['float64', 'int64'])

# Plotting correlation heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(numeric_df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

# Pairplot for relationships between variables
sns.pairplot(df, x_vars=['Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)', 'Freedom', 'Trust (Government Corruption)'],
             y_vars='Happiness Score', height=5, aspect=0.7, kind='reg')
plt.show()

# 3. Model Training:
"""Split the dataset into training and testing sets. Train a Multiple Linear Regression model on the training data."""

# Independent variables (X) and dependent variable (y)
X = df[['Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)', 'Freedom', 'Trust (Government Corruption)']]
y = df['Happiness Score']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the Multiple Linear Regression model
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)

# 4. Model Evaluation:
"""Evaluate the model's performance on the test set using appropriate metrics (e.g., R-squared, Mean Absolute Error, etc.)."""

# Predict on the test set
y_pred = lin_reg.predict(X_test)

# Calculate evaluation metrics
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("\nModel Evaluation:")
print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2): {r2}")

# 5. Model Interpretation:
"""Interpret the coefficients of the regression model. Explain the significance of each independent variable in predicting the dependent variable."""

# Coefficients of the regression model
coefficients = pd.DataFrame(lin_reg.coef_, X.columns, columns=['Coefficient'])
print("\nCoefficients of the Regression Model:")
print(coefficients)

# Interpret the significance of each independent variable
print("\nModel Interpretation:")
for i in range(len(coefficients)):
    print(f"{coefficients.index[i]}: A unit increase in this variable results in an increase of {coefficients.iloc[i, 0]:.4f} in the Happiness Score.")

"""
Significance of Each Independent Variable:

1-Economy (GDP per Capita): Typically, this is one of the strongest predictors of happiness, as economic security is fundamental to fulfilling basic needs and achieving a higher quality of life.

2-Family: Social support is crucial for emotional well-being, making it another significant predictor of happiness.

3-Health (Life Expectancy): Good health is a key component of happiness, as it directly affects one's ability to enjoy life and participate in daily activities.

4-Freedom: The ability to make life choices freely is often linked to personal fulfillment and happiness.

5-Trust (Government Corruption): Trust in institutions can play a significant role in overall happiness, as it affects feelings of security and fairness in society.

"""